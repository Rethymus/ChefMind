# 🤖 ChefMind AI 服务架构文档

## 🏗️ 架构概览

ChefMind 的 AI 服务采用插件化架构，支持多种 AI 提供商，包括 OpenAI、智谱AI、Anthropic、Google 等。通过统一的接口抽象，应用可以无缝切换不同的 AI 提供商。

## 📐 架构图

```
┌─────────────────┐    ┌──────────────────┐    ┌────────────────────┐
│   AI 服务接口    │◄───┤  AI 配置管理器    │◄───┤   应用业务逻辑层    │
└─────────────────┘    └──────────────────┘    └────────────────────┘
         │
         ▼
┌─────────────────┐    ┌──────────────────┐    ┌────────────────────┐
│ OpenAI 适配器    │    │  智谱AI 适配器    │    │ 其他提供商适配器...  │
└─────────────────┘    └──────────────────┘    └────────────────────┘
         │                       │                       │
         ▼                       ▼                       ▼
┌─────────────────────────────────────────────────────────────────────┐
│                          AI 提供商 API                              │
└─────────────────────────────────────────────────────────────────────┘
```

## 🧩 核心组件

### 1. AI 服务接口 (AIServiceInterface)

定义了所有 AI 服务必须实现的接口：

```typescript
interface AIServiceInterface {
  generateRecipe(prompt: string): Promise<Recipe>;
  analyzeNutrition(ingredients: string[]): Promise<NutritionInfo>;
  // 其他方法...
}
```

### 2. AI 配置管理器 (AIConfig)

负责管理 AI 提供商的配置信息，包括 API 密钥、模型选择、参数配置等。

### 3. AI 提供商适配器

每个 AI 提供商都有对应的适配器实现，负责将应用的请求转换为特定提供商的 API 调用。

#### OpenAI 适配器
- 支持 GPT-4、GPT-4o、GPT-3.5 等模型
- 实现流式响应处理
- 支持函数调用功能

#### 智谱AI 适配器
- 支持 GLM-4、GLM-3.5 等模型
- 支持长文本处理
- 优化中文处理能力

#### 其他提供商适配器
- Anthropic Claude
- Google Gemini
- DeepSeek
- Moonshot
- 通义千问
- 腾讯混元

## 🛠️ 配置管理

### 环境变量配置

所有 AI 提供商的 API 密钥通过环境变量配置，参考 `.env.example` 文件：

```bash
# OpenAI 配置
VITE_OPENAI_API_KEY=your_openai_api_key_here
VITE_OPENAI_MODEL=gpt-4o

# 智谱AI 配置
VITE_GLM_API_KEY=your_glm_api_key_here
VITE_GLM_MODEL=glm-4-flash
```

### 运行时配置

用户可以在应用界面中动态切换 AI 提供商和模型，配置信息存储在本地存储中。

## 🔁 缓存机制

为了提高性能和减少 API 调用成本，AI 服务实现了多级缓存机制：

1. **内存缓存** - 使用 LRU 算法缓存最近使用的响应
2. **本地存储缓存** - 将结果持久化到浏览器本地存储
3. **数据库缓存** - 将重要结果存储到 SQLite 数据库

## 📊 监控与日志

AI 服务集成了性能监控功能，记录：

- API 调用响应时间
- 成功率统计
- 错误日志
- 成本分析

## 🔒 安全考虑

1. **API 密钥保护** - 密钥存储在环境变量中，不在代码中硬编码
2. **请求限制** - 实现请求频率限制，防止滥用
3. **错误处理** - 统一的错误处理机制，避免敏感信息泄露
4. **模拟模式** - 在没有配置 API 密钥时使用模拟数据

## 🧪 测试策略

1. **单元测试** - 对每个 AI 适配器进行单元测试
2. **集成测试** - 测试完整的 AI 服务调用流程
3. **模拟测试** - 使用模拟 API 测试不同场景
4. **性能测试** - 评估不同提供商的响应时间和成本

## 🚀 扩展性

架构设计支持轻松添加新的 AI 提供商：

1. 实现 `AIServiceInterface` 接口
2. 在配置管理器中注册新的提供商
3. 更新 UI 组件以支持新的选项
4. 添加相应的测试用例

## ⚙️ 最佳实践

1. **错误重试机制** - 对网络错误实现指数退避重试
2. **超时控制** - 设置合理的请求超时时间
3. **资源清理** - 及时释放不再需要的资源
4. **版本兼容性** - 确保适配器兼容不同版本的 API